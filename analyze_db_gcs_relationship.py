#!/usr/bin/env python3
"""
ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ãƒ•ã‚¡ã‚¤ãƒ«ã¨GCSå­˜åœ¨çŠ¶æ³ã®è©³ç´°èª¿æŸ»
"""
import sqlite3
import os
import subprocess
import json

def check_gcs_file_existence():
    """ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã®GCSå­˜åœ¨çŠ¶æ³ã‚’èª¿æŸ»"""
    print("=== ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ vs GCS ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨çŠ¶æ³èª¿æŸ» ===")
    print()
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹æ¥ç¶š
    db_path = r"manual_generator\instance\manual_generator.db"
    if not os.path.exists(db_path):
        print(f"âŒ ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {db_path}")
        return
    
    conn = sqlite3.connect(db_path)
    cursor = conn.cursor()
    
    # å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    cursor.execute("""
        SELECT id, original_filename, stored_filename, file_path, file_size, uploaded_at
        FROM uploaded_files 
        ORDER BY id
    """)
    
    all_files = cursor.fetchall()
    print(f"ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹å†…ç·ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(all_files)}")
    print()
    
    # GCSä¸Šã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    print("ğŸ“ GCSä¸Šã®å…¨ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§ã‚’å–å¾—ä¸­...")
    try:
        # gcloud storage ls ã‚’ä½¿ç”¨
        result = subprocess.run([
            'gcloud', 'storage', 'ls', 'gs://manual_generator/video/', '--recursive'
        ], capture_output=True, text=True, check=True)
        
        gcs_files = []
        for line in result.stdout.strip().split('\n'):
            if line.strip() and not line.endswith(':'):
                # gs://manual_generator/video/filename.mp4 -> video/filename.mp4
                if 'gs://manual_generator/' in line:
                    relative_path = line.replace('gs://manual_generator/', '')
                    gcs_files.append(relative_path)
        
        print(f"GCSä¸Šã®ãƒ•ã‚¡ã‚¤ãƒ«æ•°: {len(gcs_files)}")
        print()
        
    except subprocess.CalledProcessError as e:
        print(f"âŒ GCS ãƒ•ã‚¡ã‚¤ãƒ«ä¸€è¦§å–å¾—ã‚¨ãƒ©ãƒ¼: {e}")
        return
    except FileNotFoundError:
        print("âŒ gcloud ã‚³ãƒãƒ³ãƒ‰ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚Google Cloud CLIãŒã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã•ã‚Œã¦ã„ãªã„å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚")
        return
    
    # è©³ç´°åˆ†æ
    analysis_results = {
        'exact_matches': [],      # å®Œå…¨ä¸€è‡´
        'missing_files': [],      # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ã‚‹ãŒGCSã«ãªã„
        'orphaned_files': [],     # GCSã«ã‚ã‚‹ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãªã„
        'duplicate_originals': {},  # åŒã˜å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã®è¤‡æ•°ãƒãƒ¼ã‚¸ãƒ§ãƒ³
        'size_groups': {}         # åŒã˜ã‚µã‚¤ã‚ºã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚°ãƒ«ãƒ¼ãƒ—
    }
    
    print("ğŸ” è©³ç´°åˆ†æé–‹å§‹...")
    
    # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ãƒ•ã‚¡ã‚¤ãƒ«ã®åˆ†æ
    for file_record in all_files:
        file_id, original_name, stored_name, file_path, file_size, upload_date = file_record
        
        # å®Œå…¨ä¸€è‡´ç¢ºèª
        if file_path in gcs_files:
            analysis_results['exact_matches'].append({
                'id': file_id,
                'original': original_name,
                'stored': stored_name,
                'path': file_path,
                'size': file_size,
                'date': upload_date
            })
        else:
            analysis_results['missing_files'].append({
                'id': file_id,
                'original': original_name,
                'stored': stored_name,
                'path': file_path,
                'size': file_size,
                'date': upload_date
            })
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        if original_name not in analysis_results['duplicate_originals']:
            analysis_results['duplicate_originals'][original_name] = []
        analysis_results['duplicate_originals'][original_name].append({
            'id': file_id,
            'stored': stored_name,
            'path': file_path,
            'size': file_size,
            'date': upload_date,
            'exists_in_gcs': file_path in gcs_files
        })
        
        # ã‚µã‚¤ã‚ºã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–
        if file_size not in analysis_results['size_groups']:
            analysis_results['size_groups'][file_size] = []
        analysis_results['size_groups'][file_size].append({
            'id': file_id,
            'original': original_name,
            'stored': stored_name,
            'path': file_path,
            'date': upload_date,
            'exists_in_gcs': file_path in gcs_files
        })
    
    # GCSä¸Šã®å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ã‚’ç‰¹å®š
    db_paths = {file_record[3] for file_record in all_files if file_record[3]}
    for gcs_path in gcs_files:
        if gcs_path not in db_paths:
            analysis_results['orphaned_files'].append(gcs_path)
    
    # çµæœå‡ºåŠ›
    print_analysis_results(analysis_results)
    
    conn.close()
    return analysis_results

def print_analysis_results(results):
    """åˆ†æçµæœã‚’æ•´ç†ã—ã¦å‡ºåŠ›"""
    
    print("=" * 80)
    print("ğŸ“Š åˆ†æçµæœã‚µãƒãƒªãƒ¼")
    print("=" * 80)
    
    print(f"âœ… å®Œå…¨ä¸€è‡´ãƒ•ã‚¡ã‚¤ãƒ«: {len(results['exact_matches'])}ä»¶")
    print(f"âŒ æ¬ æãƒ•ã‚¡ã‚¤ãƒ«: {len(results['missing_files'])}ä»¶")
    print(f"ğŸ”¸ å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆGCSã®ã¿ï¼‰: {len(results['orphaned_files'])}ä»¶")
    print()
    
    # 1. å®Œå…¨ä¸€è‡´ãƒ•ã‚¡ã‚¤ãƒ«
    if results['exact_matches']:
        print("âœ… å®Œå…¨ä¸€è‡´ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ â‡” GCSï¼‰:")
        for file_info in results['exact_matches'][:10]:  # æœ€åˆã®10ä»¶
            print(f"   ID {file_info['id']}: {file_info['original']}")
            print(f"      -> {file_info['path']}")
        if len(results['exact_matches']) > 10:
            print(f"   ... ä»– {len(results['exact_matches']) - 10}ä»¶")
        print()
    
    # 2. æ¬ æãƒ•ã‚¡ã‚¤ãƒ«
    if results['missing_files']:
        print("âŒ æ¬ æãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ã‚ã‚‹ãŒGCSã«ãªã„ï¼‰:")
        for file_info in results['missing_files']:
            print(f"   ID {file_info['id']}: {file_info['original']}")
            print(f"      DBæƒ³å®šãƒ‘ã‚¹: {file_info['path']}")
            print(f"      ã‚µã‚¤ã‚º: {file_info['size']} bytes, æ—¥ä»˜: {file_info['date']}")
        print()
    
    # 3. å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«
    if results['orphaned_files']:
        print("ğŸ”¸ å­¤ç«‹ãƒ•ã‚¡ã‚¤ãƒ«ï¼ˆGCSã«ã‚ã‚‹ãŒãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã«ãªã„ï¼‰:")
        for gcs_path in results['orphaned_files'][:10]:  # æœ€åˆã®10ä»¶
            print(f"   {gcs_path}")
        if len(results['orphaned_files']) > 10:
            print(f"   ... ä»– {len(results['orphaned_files']) - 10}ä»¶")
        print()
    
    # 4. é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æ
    print("ğŸ”„ é‡è¤‡ãƒ•ã‚¡ã‚¤ãƒ«åˆ†æï¼ˆåŒã˜å…ƒãƒ•ã‚¡ã‚¤ãƒ«åï¼‰:")
    duplicates = {k: v for k, v in results['duplicate_originals'].items() if len(v) > 1}
    
    for original_name, versions in duplicates.items():
        print(f"\nğŸ“„ å…ƒãƒ•ã‚¡ã‚¤ãƒ«å: {original_name}")
        print(f"   ãƒãƒ¼ã‚¸ãƒ§ãƒ³æ•°: {len(versions)}")
        
        existing_versions = [v for v in versions if v['exists_in_gcs']]
        missing_versions = [v for v in versions if not v['exists_in_gcs']]
        
        print(f"   GCSå­˜åœ¨: {len(existing_versions)}ä»¶, æ¬ æ: {len(missing_versions)}ä»¶")
        
        if existing_versions:
            print("   âœ… GCSå­˜åœ¨ãƒãƒ¼ã‚¸ãƒ§ãƒ³:")
            for v in existing_versions:
                print(f"      ID {v['id']}: {v['path']} ({v['date']})")
        
        if missing_versions:
            print("   âŒ GCSæ¬ æãƒãƒ¼ã‚¸ãƒ§ãƒ³:")
            for v in missing_versions:
                print(f"      ID {v['id']}: {v['path']} ({v['date']})")
    
    print()
    
    # 5. ã‚µã‚¤ã‚ºåˆ†æ
    print("ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºåˆ†æ:")
    size_duplicates = {k: v for k, v in results['size_groups'].items() if len(v) > 1}
    
    for file_size, files_with_size in sorted(size_duplicates.items(), key=lambda x: len(x[1]), reverse=True)[:5]:
        print(f"\nğŸ“¦ ã‚µã‚¤ã‚º: {file_size} bytes ({len(files_with_size)}ä»¶)")
        
        existing_files = [f for f in files_with_size if f['exists_in_gcs']]
        missing_files = [f for f in files_with_size if not f['exists_in_gcs']]
        
        print(f"   GCSå­˜åœ¨: {len(existing_files)}ä»¶, æ¬ æ: {len(missing_files)}ä»¶")
        
        # å…ƒãƒ•ã‚¡ã‚¤ãƒ«åã‚’ç¢ºèª
        original_names = list(set(f['original'] for f in files_with_size))
        if len(original_names) == 1:
            print(f"   â†’ åŒä¸€ãƒ•ã‚¡ã‚¤ãƒ«: {original_names[0]}")
        else:
            print(f"   â†’ ç•°ãªã‚‹ãƒ•ã‚¡ã‚¤ãƒ«: {len(original_names)}ç¨®é¡")

def find_potential_matches():
    """æ¬ æãƒ•ã‚¡ã‚¤ãƒ«ã«å¯¾ã™ã‚‹æ½œåœ¨çš„ãªä»£æ›¿å€™è£œã‚’æ¤œç´¢"""
    print("\n" + "=" * 80)
    print("ğŸ” æ¬ æãƒ•ã‚¡ã‚¤ãƒ«ã®ä»£æ›¿å€™è£œæ¤œç´¢")
    print("=" * 80)
    
    # ã“ã®æ©Ÿèƒ½ã¯å¾Œã§å®Ÿè£…
    print("ï¼ˆå®Ÿè£…ä¸­...ï¼‰")

if __name__ == "__main__":
    results = check_gcs_file_existence()
    if results:
        find_potential_matches()
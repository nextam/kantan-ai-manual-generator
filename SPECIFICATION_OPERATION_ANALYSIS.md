## 作業分析システム（Operation Analysis System, OAS）仕様（MVP）

### 1. 目的
- 現場の作業動画またはログから、手順単位の所要時間と発生回数を自動/半自動で算出し、改善の当たりを付けるためのレポートを短時間で作成する。

### 2. スコープ（MVP）
- 入力: 短尺動画（〜10分）または簡易操作ログ（CSV）
- 出力: 手順一覧、各手順の平均/中央値/ばらつき、タクトタイム、ボトルネック候補
- 対応現場: 単一ライン・単一作業者を前提（多人数・並列は非対象）
- 手順定義: 手動マーキング方式を優先（自動検出は実験的）
 - 追加: ユーザーが簡単なUI操作で作業分類のアノテーションを行えること（ドラフト機能）
 - 追加: ユーザーがいくつかのサンプル映像の一部をマーキングすれば、それらをもとに自動的にアノテーション・モデル強化（継続学習/自己改善）ができること（実験的）

### 3. ユースケース
1. 作業動画をアップロード
2. タイムライン上で手順の区切りをマーキング（キーフレーム/ショートカット）
3. システムが各区間の時間を集計
4. レポート（CSV/HTML）をエクスポート

### 4. 機能要件
- F1: 動画/CSVの取り込み（1ファイル/セッション）
- F2: タイムライン編集（手順ラベル、開始/終了、結合/分割、削除）
- F3: 指標計算（平均、中央値、標準偏差、合計、タクトタイム）
- F4: レポート出力（CSV/簡易HTML）
- F5: プロジェクト保存/読込（JSON）
 - F6: 作業分類アノテーションUI（簡易）
	 - 動画プレビュー、範囲指定（スライダー/時刻入力）、ラベル選択、確定/取り消し
	 - 既存アノテーションの一覧/編集/削除、重複検出の警告
 - F7: 自動アノテーションとモデル強化（実験）
	 - 部分的な手動アノテーションを教師データとして特徴量抽出→軽量分類器（例: ロジスティック回帰/SVM）を学習
	 - 非アノテーション区間への自動ラベル提案、しきい値/最小区間長でノイズ抑制
	 - ユーザーによる提案の採用/破棄により、モデルを継続学習（反復学習）

### 5. 非機能要件
- N1: ローカルPCで完結（オフライン可）
- N2: 10分・1080p動画でスムーズに操作可能（目標: 読込<5秒、編集応答<200ms）
- N3: 監査ログ（編集履歴）をJSONで保持

### 6. 画面/API（初期案）
- 画面: アップロード/プレビュー、タイムライン、統計、エクスポート
- API: `/import`, `/segments`, `/stats`, `/export`, `/project`

### 7. データモデル（簡易）
```
Project {
	id: string,
	source: { type: 'video'|'csv', path: string },
	steps: Step[]
}
Step {
	id: string,
	label: string,
	startSec: number,
	endSec: number
}
```

### 8. アルゴリズム（MVP）
- 手動マーキングを主とし、区間時間の単純集計
- 任意: シーンチェンジ検知/動き量で自動候補提示（オプション）
 - 追加（実験）: フレーム間差分/色ヒストグラム等の簡易特徴量 → 軽量分類器で作業クラス推定
	 - スムージング（移動平均/モード）と最小持続時間ルールで区間に集約

### 9. KPI/評価
- 1本の動画（〜10分）から手順化→レポート出力まで15分以内
- 手順時間の測定誤差 ±0.5秒以内（手動基準）

### 10. リスクと制約
- 自動検出の精度は現場に依存（MVPでは手動主）
- 端末スペック差によるUI遅延

### 11. 受け入れ条件
- 指定のサンプル動画で、手順マーキング→CSV/HTML出力が通る
- プロジェクト保存/読込が機能する
 - 簡易アノテーションUI上で、部分的手動ラベルから自動提案が生成され、ユーザーが採用/破棄できる

### 12. 今後の拡張
- 複数作業者/並列作業の表現
- 機械学習による自動区間推定
- OAS→MGへの手順データ連携

